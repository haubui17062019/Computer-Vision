{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDlGoWVa8Tmb"
      },
      "source": [
        "Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqm6-SIwCu_q"
      },
      "source": [
        "### 1. *gradients*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKL-wamjG7WF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "# model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "# loss = MSE\n",
        "def loss(y, y_predicted):\n",
        "  return ((y_predicted-y)**2).mean()\n",
        "#gradient\n",
        "#MSE = 1/N*(w*x - y)**2\n",
        "#dJ/dw = 1/N 2x(w*x-y)\n",
        "def gradient(x, y, y_predicted):\n",
        "  return np.dot(2*x, y_predicted-y).mean()\n",
        "print(f'prediction befor training: f(5) = {forward(5):.3f}')\n",
        "#training\n",
        "learning_rate = 0.01\n",
        "n_iters = 10\n",
        "for epoch in range(n_iters):\n",
        "  #prediction  = forward pass\n",
        "  y_pred = forward(X)\n",
        "  #loss \n",
        "  l = loss(Y, y_pred)\n",
        "  #gradients = backward pass\n",
        "  l.backward() # dl/dw\n",
        "  #update weights\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "  # zero gradients\n",
        "  w.grad.zero_()\n",
        "  if epoch %1==0:\n",
        "    print(f'epoch {epoch+1}:w = {w:.3f}, loss={l:.8f}')\n",
        "print(f'prediction after training: f(5) = {forward(5):.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROGSYQnOHMMt"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33kupEKZHO-V"
      },
      "source": [
        "### Training Pipeline\n",
        "\n",
        "1. Design Model (input, output size, forward pass)\n",
        "2. Construct loss and optimizer\n",
        "3. Training loop\n",
        "  - forward pass: compute prediction\n",
        "  - backward: gradients\n",
        "  - update weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBxxJFJeHU8N",
        "outputId": "c02cd789-21ba-4cd5-8111-4792bb6d99ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4 1\n",
            "prediction befor training: f(5) = 1.681\n",
            "epoch 1:w = 0.544, loss=20.14679337\n",
            "epoch 11:w = 1.577, loss=0.59351128\n",
            "epoch 21:w = 1.749, loss=0.08341482\n",
            "epoch 31:w = 1.782, loss=0.06625600\n",
            "epoch 41:w = 1.792, loss=0.06208117\n",
            "epoch 51:w = 1.799, loss=0.05845952\n",
            "epoch 61:w = 1.805, loss=0.05505668\n",
            "epoch 71:w = 1.811, loss=0.05185211\n",
            "epoch 81:w = 1.817, loss=0.04883402\n",
            "epoch 91:w = 1.822, loss=0.04599161\n",
            "prediction after training: f(5) = 9.643\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
        "\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "n_samples, n_features = X.shape\n",
        "print(n_samples, n_features)\n",
        "\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "#model = nn.Linear(input_size, output_size)\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    # define layers\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "print(f'prediction befor training: f(5) = {model(X_test).item():.3f}')\n",
        "#training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #prediction  = forward pass\n",
        "  y_pred = model(X)\n",
        "  #loss \n",
        "  l = loss(Y, y_pred)\n",
        "  #gradients = backward pass\n",
        "  l.backward() #dl/dw\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "    # zero gradients\n",
        "  optimizer.zero_grad()\n",
        "  if epoch %10==0:\n",
        "    [w, b] = model.parameters()\n",
        "    print(f'epoch {epoch+1}:w = {w[0][0].item():.3f}, loss={l:.8f}')\n",
        "print(f'prediction after training: f(5) = {model(X_test).item():.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-stPHV7xM5UJ"
      },
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "qk4mkWgqM9u_",
        "outputId": "80837a99-b3c8-4f40-fe0a-f8ed519518ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 10, loss = 4371.3906\n",
            "epoch: 20, loss = 3262.1052\n",
            "epoch: 30, loss = 2459.3662\n",
            "epoch: 40, loss = 1877.8456\n",
            "epoch: 50, loss = 1456.1685\n",
            "epoch: 60, loss = 1150.1212\n",
            "epoch: 70, loss = 927.8117\n",
            "epoch: 80, loss = 766.2034\n",
            "epoch: 90, loss = 648.6397\n",
            "epoch: 100, loss = 563.0606\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 0. prepare data\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
        "\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y= y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "# 1. model\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "# 2. Loss and optimizer\n",
        "learning_rate = 0.01\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3.Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  # forward pass and loss\n",
        "  y_predicted = model(X)\n",
        "  loss = criterion(y_predicted, y)\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "  # update\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if(epoch+1) % 10 == 0:\n",
        "    print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "# plot\n",
        "predicted = model(X).detach().numpy()\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWHNZECMbD06"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hANEceLnbKQL",
        "outputId": "3ee4ed41-447a-4d57-8c41-61e835983641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(455, 30)\n",
            "[[1.288e+01 1.822e+01 8.445e+01 4.931e+02 1.218e-01 1.661e-01 4.825e-02\n",
            "  5.303e-02 1.709e-01 7.253e-02 4.426e-01 1.169e+00 3.176e+00 3.437e+01\n",
            "  5.273e-03 2.329e-02 1.405e-02 1.244e-02 1.816e-02 3.299e-03 1.505e+01\n",
            "  2.437e+01 9.931e+01 6.747e+02 1.456e-01 2.961e-01 1.246e-01 1.096e-01\n",
            "  2.582e-01 8.893e-02]\n",
            " [1.113e+01 2.244e+01 7.149e+01 3.784e+02 9.566e-02 8.194e-02 4.824e-02\n",
            "  2.257e-02 2.030e-01 6.552e-02 2.800e-01 1.467e+00 1.994e+00 1.785e+01\n",
            "  3.495e-03 3.051e-02 3.445e-02 1.024e-02 2.912e-02 4.723e-03 1.202e+01\n",
            "  2.826e+01 7.780e+01 4.366e+02 1.087e-01 1.782e-01 1.564e-01 6.413e-02\n",
            "  3.169e-01 8.032e-02]]\n",
            "[1 1]\n",
            "(455, 30)\n",
            "[[-0.36180827 -0.26521011 -0.31715702 -0.46713841  1.80382609  1.18174184\n",
            "  -0.51689239  0.10653677 -0.39005152  1.39140136  0.14370971 -0.12075458\n",
            "   0.16013008 -0.13255126 -0.58631633 -0.12476339 -0.57865272  0.10906824\n",
            "  -0.28187354 -0.1889237  -0.25710149 -0.24033176 -0.2441722  -0.36688232\n",
            "   0.5448709   0.24812607 -0.71088618 -0.07967528 -0.52798733  0.2506337 ]\n",
            " [-0.8632675   0.71560604 -0.85646012 -0.79668041 -0.05863438 -0.42846033\n",
            "  -0.51701741 -0.68142992  0.7947534   0.38824034 -0.45446828  0.40088484\n",
            "  -0.43568602 -0.52155109 -1.16305609  0.27242031  0.06745547 -0.23915919\n",
            "   1.11303542  0.35017293 -0.88943217  0.38469608 -0.8880358  -0.78968152\n",
            "  -1.04286301 -0.48243034 -0.5630865  -0.76980239  0.44312729 -0.20987332]]\n",
            "tensor([[-0.3618, -0.2652, -0.3172, -0.4671,  1.8038,  1.1817, -0.5169,  0.1065,\n",
            "         -0.3901,  1.3914,  0.1437, -0.1208,  0.1601, -0.1326, -0.5863, -0.1248,\n",
            "         -0.5787,  0.1091, -0.2819, -0.1889, -0.2571, -0.2403, -0.2442, -0.3669,\n",
            "          0.5449,  0.2481, -0.7109, -0.0797, -0.5280,  0.2506],\n",
            "        [-0.8633,  0.7156, -0.8565, -0.7967, -0.0586, -0.4285, -0.5170, -0.6814,\n",
            "          0.7948,  0.3882, -0.4545,  0.4009, -0.4357, -0.5216, -1.1631,  0.2724,\n",
            "          0.0675, -0.2392,  1.1130,  0.3502, -0.8894,  0.3847, -0.8880, -0.7897,\n",
            "         -1.0429, -0.4824, -0.5631, -0.7698,  0.4431, -0.2099]])\n",
            "tensor([1., 1.])\n",
            "epoch: 10, loss = 0.2062\n",
            "epoch: 20, loss = 0.1805\n",
            "epoch: 30, loss = 0.1613\n",
            "epoch: 40, loss = 0.1466\n",
            "epoch: 50, loss = 0.1350\n",
            "epoch: 60, loss = 0.1256\n",
            "epoch: 70, loss = 0.1178\n",
            "epoch: 80, loss = 0.1112\n",
            "epoch: 90, loss = 0.1056\n",
            "epoch: 100, loss = 0.1007\n",
            "accuracy = 0.8684\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "# 0. load data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "print(X_train.shape)\n",
        "print(X_train[0:2])\n",
        "print(y_train[0:2])\n",
        "# scale\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(X_test)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_train[0:2])\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "print(X_train[0:2])\n",
        "print(y_train[0:2])\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "# 1. model\n",
        "# f = wx * b, sigmoid at the end\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, n_input_features):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = nn.Linear(n_input_features, 1)\n",
        "  def forward(self, x):\n",
        "    y_predicted = torch.sigmoid(self.linear(x))\n",
        "    return y_predicted\n",
        "\n",
        "model = LogisticRegression(n_features)\n",
        "\n",
        "# 2. loss and optimizer\n",
        "learning_rate = 0.01\n",
        "critersion=nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3. training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  # forward pass and loss\n",
        "  y_predicted = model(X_train)\n",
        "  loss = criterion(y_predicted, y_train)\n",
        "\n",
        "  # backward pass\n",
        "  loss.backward()\n",
        "  \n",
        "  # updates\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero graients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1) % 10 ==0:\n",
        "    print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "with torch.no_grad():\n",
        "  y_predicted = model(X_test)\n",
        "  y_predicted_cls = y_predicted.round()\n",
        "  acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "  print(f'accuracy = {acc:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SgyMRwHL3wE"
      },
      "source": [
        "### Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYjVZ107MDKU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "  \n",
        "  def __init__(self):\n",
        "    # data loading\n",
        "    xy = np.loadtxt('/content/9408623/wine.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n",
        "    self.x = torch.from_numpy(xy[:, 1:])\n",
        "    self.y = torch.from_numpy(xy[:, [0]]) # n_samples, 1\n",
        "    self.n_samples = xy.shape[0]\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      # dataset[0]\n",
        "      return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    # len(dataset) \n",
        "    return self.n_samples\n",
        "\n",
        "dataset = WineDataset()\n",
        "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "# training loop\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4)\n",
        "print(total_samples, n_iterations)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (inputs, labels) in enumerate(dataloader):\n",
        "    # forward backward, update\n",
        "    if (i+1) % 5 == 0:\n",
        "      print(f'epoch {epoch+1}/{num_epochs}, step{i+1}/{n_iterations}, input {inputs.shape}')\n",
        "  \n",
        "torchvision.datasets.MNIST()\n",
        "# fashion-mnist, coco\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJixhO-Ldxfd"
      },
      "source": [
        "### Dataset Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGoqlDWGd7Hf",
        "outputId": "2b4607b2-3b3b-403f-b362-52cbbe6a33f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
            " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "tensor([5.6920e+01, 6.8400e+00, 9.7200e+00, 6.2400e+01, 5.0800e+02, 1.1200e+01,\n",
            "        1.2240e+01, 1.1200e+00, 9.1600e+00, 2.2560e+01, 4.1600e+00, 1.5680e+01,\n",
            "        4.2600e+03])\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "  def __init__(self, transform):\n",
        "    xy = np.loadtxt('/content/9408623/wine.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n",
        "    self.n_samples = xy.shape[0]\n",
        "\n",
        "    # do not convert to tensor here\n",
        "    self.x = xy[:, 1:]\n",
        "    self.y = xy[:, [0]]\n",
        "    \n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sample = self.x[index], self.y[index]\n",
        "\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "    return sample\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "class ToTensor:\n",
        "  def __call__(self, sample):\n",
        "    inputs, targets = sample\n",
        "    return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "\n",
        "class MulTransform:\n",
        "  def __init__(self, factor):\n",
        "    self.factor = factor\n",
        "  \n",
        "  def __call__(self, sample):\n",
        "    inputs, target = sample\n",
        "    inputs *= self.factor\n",
        "    return inputs, target\n",
        "\n",
        "dataset = WineDataset(transform=None)\n",
        "\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features)\n",
        "print(type(features), type(labels))\n",
        "\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
        "dataset = WineDataset(transform=composed)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features)\n",
        "print(type(features), type(labels))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oxjwnx11sUw"
      },
      "source": [
        "### Softmax and Croo-Entropy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "isNllZMO1xNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf1b592a-9919-4d5e-88da-4b0fe8f37f04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax numpy:  [0.65900114 0.24243297 0.09856589]\n",
            "tensor([0.6590, 0.2424, 0.0986])\n",
            "Loss1 numpy: 0.3567\n",
            "Loss2 numpy: 2.3026\n",
            "0.3018244206905365\n",
            "1.3278342485427856\n",
            "tensor([2, 0, 1])\n",
            "tensor([0, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# Softmax\n",
        "def softmax(x):\n",
        "  return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "x = np.array([2.0, 1.0, 0.1])\n",
        "outputs = softmax(x)\n",
        "print('softmax numpy: ', outputs)\n",
        "\n",
        "x = torch.tensor([2.0, 1.0, 0.1])\n",
        "outputs = torch.softmax(x, dim=0)\n",
        "print(outputs)\n",
        "\n",
        "# Cross-Entropy\n",
        "def cross_entropy(actual, predicted):\n",
        "  loss = -np.sum(actual * np.log(predicted))\n",
        "  return loss\n",
        "\n",
        "Y = np.array([1, 0, 0])\n",
        "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
        "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
        "l1 = cross_entropy(Y, Y_pred_good)\n",
        "l2 = cross_entropy(Y, Y_pred_bad)\n",
        "print(f'Loss1 numpy: {l1:.4f}')\n",
        "print(f'Loss2 numpy: {l2:.4f}')\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "# 3 sample \n",
        "Y = torch.tensor([2, 0, 1])\n",
        "# n_sample x nclasses = 3x3\n",
        "Y_pred_good = torch.tensor([[0.1, 1.0, 2.1], [2.0, 1.0, 0.1], [0.1, 3.0, 0.1]])\n",
        "Y_pred_bad = torch.tensor([[2.1, 1.0, 0.1], [0.1, 1.0, 0.1], [0.1, 3.0, 0.1]])\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "print(l1.item())\n",
        "print(l2.item())\n",
        "\n",
        "_, prediction1 = torch.max(Y_pred_good, 1)\n",
        "_, prediction2 = torch.max(Y_pred_bad, 1)\n",
        "print(prediction1)\n",
        "print(prediction2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pAvtrUzt7gIX"
      },
      "outputs": [],
      "source": [
        "# Multiclass problem\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# option 1 (create nn modules)\n",
        "class NeuralNet1(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet1 , self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.linear1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear2(out)\n",
        "    # no softmax in the end\n",
        "    return out\n",
        "\n",
        "model = NeuralNet1(input_size = 28*28, hidden_size=5, num_classes=3)\n",
        "criterion =   nn.BCELoss() #(applies softmax)\n",
        "\n",
        "# option 2 (use activation functions driectly in forward pass)\n",
        "class NeuralNet2(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(NeuralNet2, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = torch.relu(self.linear1(x))\n",
        "    out = torch.sigmoid(self.linear2(out))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7IadiVkfLfb"
      },
      "source": [
        "### Feed Forward Net\n",
        "1. MNIST\n",
        "2. Dataloader, Transform\n",
        "3. Multilayer, Neural Net, activation function\n",
        "4. loss and optimizer\n",
        "5. traning and loop (batch training)\n",
        "6. model evaluation\n",
        "7. GPU support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HZFn_8CFfOeZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9255a82-1ef6-4759-a3fe-4244e870f7c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 162889974.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/data/MNIST/raw/train-images-idx3-ubyte.gz to /content/data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 105427061.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/data/MNIST/raw/train-labels-idx1-ubyte.gz to /content/data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 66315313.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/data/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 18622217.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
            "epoch 1 / 2, step 100/600, loss = 0.3214\n",
            "epoch 1 / 2, step 200/600, loss = 0.3067\n",
            "epoch 1 / 2, step 300/600, loss = 0.3003\n",
            "epoch 1 / 2, step 400/600, loss = 0.3744\n",
            "epoch 1 / 2, step 500/600, loss = 0.2118\n",
            "epoch 1 / 2, step 600/600, loss = 0.2197\n",
            "epoch 2 / 2, step 100/600, loss = 0.1764\n",
            "epoch 2 / 2, step 200/600, loss = 0.2859\n",
            "epoch 2 / 2, step 300/600, loss = 0.1620\n",
            "epoch 2 / 2, step 400/600, loss = 0.2682\n",
            "epoch 2 / 2, step 500/600, loss = 0.1872\n",
            "epoch 2 / 2, step 600/600, loss = 0.2223\n",
            "accuracy = 95.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# device config\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# hyper parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 100\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST\n",
        "train_dataset = torchvision.datasets.MNIST(root='/content/data', train=True,\n",
        "                                           transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='/content/data', train=False,\n",
        "                                           transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
        "                                      shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
        "                                      shuffle=False)\n",
        "\n",
        "examples = iter(train_loader)\n",
        "samples, labels = next(examples)\n",
        "print(samples.shape, labels.shape)\n",
        "\n",
        "# for i in range(6):\n",
        "#   plt.subplot(2, 3, i+1)\n",
        "#   plt.imshow(samples[i][0], cmap='gray')\n",
        "# plt.show()\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes)\n",
        "\n",
        "# loss and opitimize\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# train loop\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # 100, 1, 28, 28\n",
        "    # 100, 784\n",
        "    images = images.reshape(-1, 28*28)\n",
        "    labels = labels\n",
        "\n",
        "    # forward\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "      print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
        "  \n",
        "# test \n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.reshape(-1, 28*28)\n",
        "    labels = labels\n",
        "    outputs = model(images)\n",
        "\n",
        "    # value, index\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    n_samples += labels.shape[0]\n",
        "    n_correct += (predictions == labels).sum().item()\n",
        "  \n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'accuracy = {acc}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h07eqVQ8PQs"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2RTPKvZU8R90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ebc847-3036-4d5c-b359-d8713aff7f9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 28831358.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/data/cifar-10-python.tar.gz to /content/data\n",
            "Files already downloaded and verified\n",
            "accuracy = 42.06 %\n",
            "Accuracy of plane: 32.6 %\n",
            "Accuracy of car: 70.5 %\n",
            "Accuracy of bird: 15.2 %\n",
            "Accuracy of cat: 19.2 %\n",
            "Accuracy of deer: 26.3 %\n",
            "Accuracy of dog: 33.7 %\n",
            "Accuracy of frog: 65.3 %\n",
            "Accuracy of horse: 55.9 %\n",
            "Accuracy of ship: 60.9 %\n",
            "Accuracy of truck: 41.0 %\n"
          ]
        }
      ],
      "source": [
        "# !pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# hyper-parameters\n",
        "num_epochs = 4\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "\n",
        "# dataset has PILImage image of range[0, 1]\n",
        "# we transform them to Tensors of normalized range [-1, 1]\n",
        "# transform = transforms.Compose([transforms.ToTensor(),\n",
        "#                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='/content/data', train=True,\n",
        "                                             download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='/content/data', train=False,\n",
        "                                             download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=batch_size,shuffle=True,\n",
        "                                           num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                           batch_size=batch_size,shuffle=False,\n",
        "                                          num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# examples = iter(train_loader)\n",
        "# samples, labels = next(examples)\n",
        "# print(len(examples))\n",
        "\n",
        "# implement conv Net\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 32, 5)\n",
        "    self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv3 = nn.Conv2d(64, 128, 5)\n",
        "    self.conv4 = nn.Conv2d(128, 256, 5)\n",
        "    self.fc1 = nn.Linear(256*2*2, 128)\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.conv1(x))\n",
        "    x = self.pool(torch.relu(self.conv2(x)))\n",
        "    x = torch.relu(self.conv3(x))\n",
        "    x = self.pool(torch.relu(self.conv4(x)))\n",
        "    x = x.view(-1, 256*2*2) # Flatten\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = torch.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x  \n",
        "    \n",
        "\n",
        "model = ConvNet()\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# train loop\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # 4, 3, 32, 32\n",
        "    # forward\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # if (i+1) % 200 == 0:\n",
        "    #   print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
        "  \n",
        "# test\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  n_class_correct = [0 for i in range(10)]\n",
        "  n_class_samples = [0 for i in range(10)]\n",
        "  for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    # max return (value, index)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    n_samples += labels.size(0)\n",
        "    n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      label = labels[i]\n",
        "      pred = predicted[i]\n",
        "      if (label == pred):\n",
        "        n_class_correct[label] += 1\n",
        "      n_class_samples[label] += 1\n",
        "  \n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'accuracy = {acc} %')\n",
        "\n",
        "  for i in range(10):\n",
        "    acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "    print(f'Accuracy of {classes[i]}: {acc} %')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV3M-w7isPRu"
      },
      "source": [
        "### Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWvHQdsZ9arC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install tensorboardcolab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enyw9ayM-H7f",
        "outputId": "191438c8-94ed-4334-9457-89eaf5130f4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://544d-35-231-75-29.ngrok.io\n"
          ]
        }
      ],
      "source": [
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "tbc = TensorBoardColab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "0d5f831b311c43ad96b8b2fbb254303a",
            "bd00f169cbc644268beb97f62044800c",
            "05095994215d44e894b79d67f2b40dcb",
            "0e26986ff29a4fe38df1d58cee9d4646"
          ]
        },
        "id": "VoeO25rdsSk_",
        "outputId": "d5285271-53de-4331-98dc-91d18535577f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d5f831b311c43ad96b8b2fbb254303a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/data/MNIST/raw/train-images-idx3-ubyte.gz to /content/data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd00f169cbc644268beb97f62044800c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/data/MNIST/raw/train-labels-idx1-ubyte.gz to /content/data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05095994215d44e894b79d67f2b40dcb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/data/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e26986ff29a4fe38df1d58cee9d4646",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/data/MNIST/raw\n",
            "\n",
            "epoch 1 / 2, step 100/600, loss = 0.4575\n",
            "epoch 1 / 2, step 200/600, loss = 0.3490\n",
            "epoch 1 / 2, step 300/600, loss = 0.4071\n",
            "epoch 1 / 2, step 400/600, loss = 0.2291\n",
            "epoch 1 / 2, step 500/600, loss = 0.2611\n",
            "epoch 1 / 2, step 600/600, loss = 0.2377\n",
            "epoch 2 / 2, step 100/600, loss = 0.1253\n",
            "epoch 2 / 2, step 200/600, loss = 0.2729\n",
            "epoch 2 / 2, step 300/600, loss = 0.3240\n",
            "epoch 2 / 2, step 400/600, loss = 0.1091\n",
            "epoch 2 / 2, step 500/600, loss = 0.2718\n",
            "epoch 2 / 2, step 600/600, loss = 0.1775\n",
            "accuracy = 95.4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# device config\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# hyper parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 100\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST\n",
        "train_dataset = torchvision.datasets.MNIST(root='/content/data', train=True,\n",
        "                                           transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='/content/data', train=False,\n",
        "                                           transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
        "                                      shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
        "                                      shuffle=False)\n",
        "\n",
        "examples = iter(train_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "# for i in range(6):\n",
        "#   plt.subplot(2, 3, i+1)\n",
        "#   plt.imshow(samples[i][0], cmap='gray')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# loss and opitimize\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "# train loop\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # 100, 1, 28, 28\n",
        "    # 100, 784\n",
        "    images = images.reshape(-1, 28*28)\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # forward\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "      print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
        "  \n",
        "# test \n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.reshape(-1, 28*28)\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    # value, index\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    n_samples += labels.shape[0]\n",
        "    n_correct += (predictions == labels).sum().item()\n",
        "  \n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'accuracy = {acc}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Xqm6-SIwCu_q",
        "33kupEKZHO-V",
        "-stPHV7xM5UJ",
        "wWHNZECMbD06",
        "-SgyMRwHL3wE",
        "cJixhO-Ldxfd",
        "-oxjwnx11sUw",
        "YV3M-w7isPRu"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}